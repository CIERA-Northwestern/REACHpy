{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy: Python tools for science\n",
    "*Monica Rizzo, 2019*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the many useful python packages for data analysis, SciPy is one of the most commonly used and widely applicable. In this notebook we're going to be going over some of the functions in Scipy you can use to fit and model data. \n",
    "\n",
    "First things first, lets import all of the important stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import factorial\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "from scipy.integrate import quad\n",
    "from scipy.misc import derivative\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#this makes the plot labels bigger (looks nicer)\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of things you can do with data. Often times, we will want to either 1) see how well data agrees with a given model or 2) without assuming anything, see what sort of model agrees the best with some data.\n",
    "One way to test this is by using regression techniques. \"Regression\" is just the math word for fitting data to a certain function. You may have done something similar to this before with Excel, or by hand using graph paper. \n",
    "\n",
    "Lucky for us, SciPy can fit things for you! First, lets generate some data that follows a known function.\n",
    "1. **Using numpy, create an array of n equally spaced x values within some range - doesn't really matter what range**\n",
    "2. **Then choose two values for the slope m and y intercept b**\n",
    "3. **Finally, create a numpy array of y values which follows the equation for a line (*hint: take advantage of numpy array addition/multiplication*)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of data points to generate\n",
    "n = #complete\n",
    "\n",
    "#create a numpy array of x values   \n",
    "x_values = #complete\n",
    "\n",
    "#define slope and y intercept\n",
    "m = #complete\n",
    "b = #complete\n",
    "\n",
    "#make an array of y values that follow the equation of a line\n",
    "y_values = #complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the data to see what it looks like (always a good first step).\n",
    "1. **Make a scatter plot of the x and y values you created above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "#complete\n",
    "plt.grid(True)\n",
    "#ALWAYS LABEL YOUR AXES\n",
    "plt.xlabel(#complete\n",
    "plt.ylabel(#complete\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we already know what this function looks like, so we already know what Scipy should return as the answer. \n",
    "\n",
    "The Scipy function we are going to use to do the fitting is called *curve_fit*. Using a user-defined python function that describes the fit (in this case a line), *curve_fit* will attempt to find the best fitting parameters for some input data. So, in this case, we want to create a fit function that returns a line and takes 2 free parameters: the slope and the y intercept. Then, we want to hand *curve_fit* that fit function, the x data, and the y data, and it's going to tell us what it thinks the best fitting parameters are, along with the uncertainties on those parameters (which we're not going to worry about right now).\n",
    "\n",
    "1. **Define a function which takes as inputs x, m, and b, and returns the y values corresponding to a line**\n",
    "2. **Pass *curve_fit* the name of your fit function, your x data, and your y data (see documentation here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html)**\n",
    "3. **Print the result of *curve_fit* (note: result should be a 2 element array. The values are in the same order as the arguments of your fit function)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_function():\n",
    "    #complete\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, cov = curve_fit(#complete\n",
    "\n",
    "#print the result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice.\n",
    "\n",
    "![Alt Text](https://media.giphy.com/media/XreQmk7ETCak0/giphy.gif)\n",
    "\n",
    "Now let's look at a more realistic example. In real life, data is noisy and usually has some associated uncertainty. Lets add a little bit of noise to our existing data, and assign some uncertainty.\n",
    "\n",
    "1. **Add the noise values to your array of y values**\n",
    "2. **Create an array - which will be your y error - of length n where all of the values are 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy has built-in capabilities to generate random numbers :)\n",
    "#this will generate random numbers drawn from a bell curve\n",
    "y_noise = np.random.normal(0, 3, n)\n",
    "\n",
    "#array of y values plus noise\n",
    "y_noisy_values = #complete\n",
    "\n",
    "#array uncertainty values\n",
    "y_error = #complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the data again. \n",
    "\n",
    "***Hint: in order to plot the errors, instead of using the 'plot' function, use 'errorbar': https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.errorbar.html***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "#try using fmt='o' and markersize=6.0\n",
    "plt.errorbar(#complete\n",
    "#complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so pretty anymore, but maybe still looks like a line? Let's see what SciPy thinks. \n",
    "1. **Using the same syntax as before, pass *curve_fit* your fit function, your x data, your noisy y data, and also the uncertainty on your y values - this can be done using the 'sigma' option.**\n",
    "2. **As before, print the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use curve fit to find the fit parameters for your noisy data\n",
    "result, cov = curve_fit(#complete\n",
    "\n",
    "#print the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this answer is pretty different from the actual values of the parameters. We can plot what the fit looks like over our data to visually assess how bad/good it is. \n",
    "1. **Create a numpy array of *n_test* x values to plot, that has a range that is slightly bigger that the range of your x values**\n",
    "2. **Pass this array, along with the best fit m and b values, to your fit function, and store the result as a separate array**\n",
    "3. **Copy the cell you used to plot the data with errorbars, and add a line to plot the test x and y values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of test values\n",
    "n_test = 500\n",
    "\n",
    "#array of x test values\n",
    "x_test_values = #complete\n",
    "\n",
    "#array of y test values \n",
    "y_test_values = fit_function(#complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "#complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that these answers are just guesses - they also have some uncertainty to them. The other thing that *curve_fit* returns - which we're calling *cov* - describes the uncertainites on the fit parameters. Let's see what those look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cov is a matrix, and we only want the diagonal values\n",
    "unc = np.sqrt(np.diag(cov))\n",
    "\n",
    "print(\"param1_err = %0.2f and param2_err = %0.2f\" % (unc[0], unc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given what your data looks like, do you think these numbers are reasonable? Do your fit parameters to the noisy data agree with the real parameters within this uncertainty?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's switch gears a little bit. Suppose we have some data where instead of the function parameters (slopes, y-intercepts, etc.), we want to approximate what the values between our data points are. So in this case, we don't care about the specifics of the fit, we just want to connect the dots. This can be achieved using *interpolation* techniques. \n",
    "\n",
    "First, lets again create some data that follows a known function:\n",
    "1. **Using numpy arrays, create an array of 10 x values that ranges from 0 to 2$\\pi$**\n",
    "2. **Create an array of y values which is the sine of the x values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of x values\n",
    "x_values = #complete\n",
    "\n",
    "#array of y values\n",
    "y_values = #complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per *always*, plot your data before doing anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "#complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could be sine curve - and I'm sure if you connected the dots by hand you would draw something that resembles a sine function. But let's see how well we can approximate this by numerically interpolating. To start, let's use the default settings of *interp_1d*. When passed x and y values, *interp_1d* will return a function which interpolates the data at every point between the maximum and minimum x value. We can then plot the values of this interpolation function over a range of test x values. \n",
    "\n",
    "1. **Pass *interp1d* your x and y values (see documentation here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp1d.html#scipy.interpolate.interp1d)**\n",
    "2. **Create an array of *n_test* test x values between 0 and 2$\\pi$**\n",
    "3. **Pass your interpolation function your array of test x values and store the result as test y values**\n",
    "4. **Plot your test values as a line over a scatter plot of your data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an interpolation function\n",
    "interp_func = interp1d(#complete\n",
    "\n",
    "#array of test x values\n",
    "x_test_values = #complete\n",
    "\n",
    "#recall that interp_func is a function, so it can be used like any other function\n",
    "y_test_values = #complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "#complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, *interp_1d* connects the data points with straight lines by default. This isn't always the best way to interpolate data; we can tell just by looking at what we've plotted that our data most likely has some curvature to it. It's also generally better to interpolate data smoothly, because this makes performing operations like differentiation easier/more accurate. Lets try out some different types of interpolation.\n",
    "\n",
    "To change the way *interp_1d* connects our data points, we can use the 'kind' option.\n",
    "1. **Try setting kind to each of the following: 'zero', 'quadratic', 'cubic'. For each different kind, create a new variable name to store the interpolating function in.**\n",
    "2. **Using the same method as above, plot the data and the interpolated approximation on top of each other. You can use the same test x values, but will need to create new test y values for each plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_func_zero = interp1d(x_values, y_values, kind='zero')\n",
    "#repeat for all interpolation kinds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test y values\n",
    "\n",
    "#zero plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test y values\n",
    "\n",
    "#quadratic plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test y values\n",
    "\n",
    "#cubic plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we judge which of these kinds of interpolation is the best? We know what the values of the function *should* be, so we can just pick a point and see how different the approximate answer is from the real answer. In the cell below, check to see how different each of the approximate y values is from the real value where x = 4. \n",
    "\n",
    "1. **Compute the real value - sin(4) - and store in a variable**\n",
    "2. **For each of the interpolation functions, compute and store in different variables the approximate y value at an x value of 4**\n",
    "3. **Calculate and print the percent error of each of the approximate y values**\n",
    "\n",
    "*Hint: calculate percent error using: \\begin{equation}\\frac{|approximation - real|}{|real|} \\times 100\\end{equation}*\n",
    "\n",
    "*Hint: python has a built in absolute value function called 'abs'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_value = np.sin(4)\n",
    "\n",
    "approx_value_linear = interp_func(4)\n",
    "#repeat for all interpolation functions\n",
    "\n",
    "#calculate percent error for each interpolation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, which appears to be the best kind of interpolation? This happens to be the best kind in general. \n",
    "\n",
    "*Optional*: We can also check to make sure the area under the curve is what we expect it to be. For a sine curve in the range zero to 2$\\pi$, the total area should be zero - this is because half the the curve is above zero and half is below. In order to find the area under the curve, we can *integrate* it - SciPy also has functions to do this. The particular algorithm we're going to use is called *quad* (which is all around the most accurate in SciPy). *quad* takes as arguments the name of the function you want to integrate, the upper bound of the integration, and the lower bound of the integration. \n",
    "\n",
    "1. **For each of the interpolation functions, use quad to integrate from 0 to 2$\\pi$ (see documentation here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.quad.html#scipy.integrate.quad)**\n",
    "2. **Print out the result of each. Why do you think the results are what they are?**\n",
    "\n",
    "*Note: when dealing with computers, numbers smaller than or close to $10^{-16}$ are considered zero*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_linear, err = quad(interp_func, 0, 2*np.pi)\n",
    "#repeat for all interpolation functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Root Finding \n",
    "\n",
    "Now let's talk - briefly - about something completely different. In math classes, you may have needed to find the zeros of functions before (set y equal to zero and solve for x). Finding zeros is very important in the area of numerical optimization - which we won't talk about explicity - but can often be more complicated than just setting y equal to zero and solving for x. In fact, when you have just data points, you often can't do this at all. \n",
    "\n",
    "And that's where SciPy comes in. Suppose we have some interpolating function which passes through zero, and we want to know approximately where. One of the best algorithms to do this is something called *Brent's method* (which you may or may not learn about in college). *Brent's method* will attempt to find where a function crosses zero in a given interval; it needs to know the endpoints to look between in order to work. \n",
    "\n",
    "First, lets create some data to try this out on:\n",
    "1. **Using numpy, create an array of 10 equally spaced x values between -2 and 2**\n",
    "2. **Create an array of y values that is the x values cubed plus 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of x values\n",
    "x_values = #complete\n",
    "\n",
    "#array of y values\n",
    "y_values = #complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "#complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plot, at what x value do you expect the zero point to be? \n",
    "\n",
    "Let's see what SciPy thinks. We're going to use a function called *brentq*. This function takes the name of the function you want the zero of, the upper bound of that function, and the lower bound of that function. So first, we need to interpolate the data, and then pass that interpolant to *brentq*.\n",
    "\n",
    "1. **Using the best interpolation kind from the previous section, create and store an interpolating function for your x and y data**\n",
    "2. **Pass *brentq* the name of your interpolating function, the lower bound of the function, and the upper bound of the function (see documentation here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.brentq.html#scipy.optimize.brentq)**\n",
    "3. **Print the result. Does this answer seem correct?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolating function\n",
    "interp_func = interp1d(#complete\n",
    "\n",
    "#find zero using brentq\n",
    "x0 = brentq(#complete\n",
    "\n",
    "#print result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fun With Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tackle a (sort of) real-life example. Using the provided data file, we will attempt to fit the data it contains with a more complicated fit function. First, we will load and plot the data.\n",
    "\n",
    "1. **Load the data and plot it (with error bars)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data and store it to an array\n",
    "#columns: x values, y values, y error\n",
    "data = #complete\n",
    "\n",
    "#split the data into separate x, y, and y_err arrays using numpy array slicing\n",
    "x_values = #complete\n",
    "y_values = #complete\n",
    "y_error = #complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot. that. data\n",
    "plt.figure(figsize=(10, 8))\n",
    "#complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think this function looks like? Using your knowledge of regression, try to think of a fitting function which might model this data, and then fit that model to the data.\n",
    "\n",
    "1. **Define a fitting function, and fit it to the data using *curve_fit***\n",
    "2. **Print the best fit parameters and their uncertainties**\n",
    "3. **Plot the data and the fit on top of each other**\n",
    "\n",
    "*Hint: try to fit a higher order polynomial*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a fitting function\n",
    "def :\n",
    "\n",
    "#use curve fit to fit the function to the data\n",
    "result, cov = #complete\n",
    "\n",
    "#print the result and the uncertainties\n",
    "#you can probably just copy and paste code from the first section, with minor adjustments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create test x values, and test y values from the fit\n",
    "\n",
    "#plot the data and the fit \n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "#complete\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data actually has a function which fits it best, for science reasons. In order to fit that function we're going to cheat a little and find the location of the peak, i.e. where the slope of the function equals zero. To do this, we need to first interpolate our data, and then find where the slope (or *derivative*) equals zero. \n",
    "\n",
    "1. **Interpolate the data using the best kind of interpolation**\n",
    "2. **Define a function that takes x values and returns the derivative of your interpolation function at those x values (already completed for you)**\n",
    "3. **Pass the derivative function to *brentq* (remember you need to pass it a lower and upper bound), and store the result. Print this result. Does it make sense?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolation function \n",
    "interp_func = interp1d(#complete\n",
    "\n",
    "#function which takes x values and returns derivative\n",
    "def deriv_func(x):\n",
    "    \n",
    "    deriv = derivative(interp_func, x, dx = 1e-6)\n",
    "    \n",
    "    return deriv\n",
    "\n",
    "#find root of derivative function \n",
    "x0 = brentq(#complete\n",
    "\n",
    "#print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function we want to fit to is:\n",
    "\n",
    "\\begin{equation}f(x) = a ((x/x0)^{b1/-0.8} + (x/x0)^{b2/-0.8})^{-0.8},\\end{equation}\n",
    "\n",
    "where a, b1, and b2 are the three fit parameters. Now that we know x0, we can use *curve_fit* to find the remaining 3 parameters.\n",
    "\n",
    "1. **Define a function called 'broken_power_law' which takes x values, a, b1, and b2 as input and returns the values corresponding to the above expression**\n",
    "2. **Use curve fit to fit this function to the data, *including the error***\n",
    "3. **Plot the data and the fit on top of each other. Would you say this fit is good or bad? Why or why not?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to return the expression above\n",
    "def broken_power_law:\n",
    "    #complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the above function using curve fit\n",
    "result, cov = curve_fit(broken_power_law, x_values, y_values, sigma=y_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create test x and y values \n",
    "\n",
    "#plot the data with error and the fit\n",
    "plt.figure(figsize=(10, 8))\n",
    "#complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Fun Stuff: Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as cool and useful tools go, SciPy has a *ton* of other nifty functions (with decent documentation), for almost every application. The data above is from a course I took on radiative processes in astrophysics (which is a complicated way of saying \"light curves: the class\"). You can learn various things about the object which produced this light curve by finding the slope of each side of the logarithm of the data. This is just one idea of something you can do with this data besides just fitting it.   \n",
    "\n",
    "See what else you can do with it!\n",
    "\n",
    "Some ideas:\n",
    "\n",
    "* try a different fitting function\n",
    "* interpolate the data\n",
    "* find the point where the slope of the data is zero\n",
    "* integrate/differentiate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##play around with the data and see what you can do with it\n",
    "##if you need help or suggestions, don't hesitate to ask!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources \n",
    "\n",
    "A set of SciPy tutorials and documentation can be found here: https://docs.scipy.org/doc/scipy/reference/index.html\n",
    "\n",
    "The Scipy Lectures site also has a pretty comprehensive guide to all of the modules: https://scipy-lectures.org/intro/scipy.html\n",
    "\n",
    "Here is a nifty explanation of the difference between regression and interpolation (which I found useful): https://stats.stackexchange.com/questions/33659/how-is-interpolation-related-to-the-concept-of-regression\n",
    "\n",
    "Here is a lecture (which is honestly pretty heavy, but if you want to look through it you can) on numerical root finding methods: http://butler.cc.tut.fi/~piche/numa/lecture0506.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
