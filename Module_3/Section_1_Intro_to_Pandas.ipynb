{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgFQ0jMkuMa8"
      },
      "source": [
        "# Section 1. Intro to Pandas\n",
        "\n",
        "We have used Python lists and Numpy arrays to store and manipulate data.\n",
        "Each method has its place in a Python program. \n",
        "But there's an excellent Python package called Pandas that greatly facilitates handling data and more importantly, managing data from files. \n",
        "Pandas uses the DataFrame, which can be thought of as a large table with built-in functions to:\n",
        "- process rows and columns\n",
        "- read and write to many different formats on disk\n",
        "- interact with other DataFrames. \n",
        "\n",
        "One key advantage of pandas over other types of data storage is that it can easily handle manage many different data types.\n",
        "\n",
        "## 1.1 Getting Started\n",
        "\n",
        "First, we need to import the package. We should also import NumPy for other useful functions and matplotlib for when we plot\n",
        "```\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdPe93y5uB-r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhOD9Xto_DNx"
      },
      "source": [
        "### 1.1.1 The DataFrame\n",
        "\n",
        "Here, we will demonstrate how to create a DataFrame using lists. \n",
        "First, let's define some familiar looking Solar System data.\n",
        "\n",
        "```\n",
        "planets = [['Mercury', 0.0553, 0.4, 0],\n",
        "           ['Venus', 0.815, 0.7, 0],\n",
        "           ['Earth', 1.0, 1.0, 1],\n",
        "           ['Mars', 0.107, 1.5, 2],\n",
        "           ['Jupiter', 317.8, 5.2, 95],\n",
        "           ['Saturn', 95.2, 9.5, 146],\n",
        "           ['Uranus', 14.5, 19.2, 28],\n",
        "           ['Neptune', 17.1, 30.1, 16]]\n",
        "\n",
        "colnames = ['Name','Mass','Distance','N_moons']\n",
        "# Units: None, Earth Masses, AU, None\n",
        "```\n",
        "\n",
        "Take note of a few things here. \n",
        "\n",
        "First, unlike in NumPy arrays, where you can only have one data type (usually int or float), each row in the above table mixes three different types of data: string, float, and int. This is one of the advantages of Pandas: different columns are allowed to have different data types.\n",
        "\n",
        "Second, notice that the code above uses a second list to create names for the columns. This is a huge feature of the design philosophy of the DataFrame. While a NumPy 2D array can be thought of as a huge matrix of numbers, a DataFrame really is a table. \n",
        "\n",
        "Finally, the code included a comment with the units associated with this data. Units were not included in the column names to keep the column names short, which helps writing the code later on be much easier. As a reminder, it is good practice to label units in your code with comments to stay organized and to be able to share your code with others so they can easily understand it.\n",
        "\n",
        "Now, let's make a dataframe named `df` from the lists named `planets` and show it.\n",
        "```\n",
        "df = pd.DataFrame(planets, columns=colnames)\n",
        "print(df)\n",
        "\n",
        "```\n",
        "In the second cell, try running just `df` to see how the output may look different. This distinction is only relevant when working in a Jupyter notebook and when datasets are small enough to read and look over in Python.\n",
        "```\n",
        "df\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUlfOT4_gV8E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY4XVvbgfhsk"
      },
      "source": [
        "### 1.1.2 Accessing Rows and Cells\n",
        "\n",
        "To access individual rows, we use the method `df.loc`, where you can replace df with the name of your DataFrame.\n",
        "\n",
        "In the previous example above, the indices ranged from 0 to 7. So, if we want to access the row for Earth, we can execute\n",
        "```\n",
        "df.loc[2]\n",
        "```\n",
        "Note that DataFrames can use different indexes. For instance, the indices may not correspond to their row number at all. In fact, you can even find tables where the indices are strings. When using `df.loc` you must remember to use the label given.\n",
        "\n",
        "To access a specific cell, we specify both the index (as above) and the column name. For example, if we want to get the mass of Venus, we can execute\n",
        "```\n",
        "df.loc[2,'Mass']\n",
        "```\n",
        "Try this in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYPeOdeciGKr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5pUCr2UB98p"
      },
      "source": [
        "Note that we can also use this functionality with `.loc` to \n",
        "change the values of individual cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRxCRggdiZbk"
      },
      "source": [
        "### 1.1.3 Accessing Columns\n",
        "\n",
        "Accessing individual rows and cells is less useful than you may think since each row only represents one data point. When we're using tables, we're often more interested in the statistics of many data points. The DataFrame structure represents this, because it's very easy to obtain different columns. For example, if we want masses, we could use\n",
        "```\n",
        "df['Mass']\n",
        "```\n",
        "If we want multiple columns, we enter a list of column names, e.g.,\n",
        "```\n",
        "df[['Mass','Distance']]\n",
        "```\n",
        "\n",
        "Note that this is why it is best to keep column names short by including units in a comment rather than in the column name as mentioned above. Since we need to write out the column names, adding the units can make the code unnecessarily long."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evfVfW2CiN92"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtFBqIS7po2g"
      },
      "source": [
        "### 1.1.4 df.values\n",
        "When using some functions, such `plt.plot()`, we don't need a full Pandas DataFrame. Using `df.values` will extract the values and return a NumPy array.\n",
        "```\n",
        "df.values # returns a 2D array\n",
        "df.loc[2].values # returns a 1D array of the third row\n",
        "df['Mass'].values # returns a 1D array of the Mass column\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9I5z5sGr1he"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jFSOPt0r0oE"
      },
      "source": [
        "## 1.2 Making Changes to a DataFrame\n",
        "### 1.2.1 Adding New Columns from Data\n",
        "\n",
        "Suppose we obtain additional data, and we want to add it to our DataFrame. We can do so like this.\n",
        "```\n",
        "radii = [0.383, 0.949, 1, 0.532, 11.21, 9.45, 4.01, 3.88] # in Earth radii \n",
        "\n",
        "df['Radius'] = radii\n",
        "```\n",
        "\n",
        "One big caveat: **your list must be ordered in the same way as your DataFrame.**\n",
        "\n",
        "Add this new column in the next code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "el9h05K5sRGl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnyUwre6sRp2"
      },
      "source": [
        "### 1.2.2 Adding New Columns based on Existing Columns\n",
        "\n",
        "Columns are essentially NumPy arrays with extra information. \n",
        "As a result, we can do mathematical operations on columns just like we do with arrays. \n",
        "We can leverage this to create new columns. \n",
        "For example, we want to create a new column with the density of each planet. Density is the ratio of the mass of an object over its volume, and we can calculate the densities by using the formula $d = m / v$.  Our DataFrame contains planetary mass in Earth masses and radius data in Earth radius. As a result, we'll convert the masses and radii to SI units, calculate the densities using those values, and add a column named Density to the DataFrame `df`.\n",
        "```\n",
        "m_e = 5.9722e24 # kg\n",
        "r_e = 6.371e6 # m, using the average radius\n",
        "df['Density'] = m_e*df['Mass']/((4/3)*np.pi*(r_e*df['Radius'])**3)\n",
        "```\n",
        "\n",
        "What do you notice about the densities of the outer planets versus the inner planets? Compare these densities to the densities of various materials in this [wikipedia page](https://en.wikipedia.org/wiki/Density#Densities). Which materials are these densities most similar to?\n",
        "\n",
        "What you should find is that the inner planets are rocky, so their densities are more comparable to metals, while the gas giants have densities that are closer to that of water."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhQvBYew5Y2g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTndNlqg0b1r"
      },
      "source": [
        "### 1.2.3 Practice Problem 1: Kepler's Law\n",
        "\n",
        "Using Kepler's Third Law, make another column that corresponds to the orbital period for each planet **in years.** Once again, Keplers Third Law is \n",
        "\n",
        "$$T = 2\\pi \\sqrt{\\frac{a^3}{G(M_1 + M_2)}}$$\n",
        "\n",
        "For the case of solar system planets, you may make the approximation that $M_1 + M_2 \\approx M_\\odot$. \n",
        "\n",
        "You can calculate by hand how many seconds are in a year, but note a year technically has 365.25 days. \n",
        "\n",
        "Use the Astronomical Quantities notebook for the other quantities you need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMpWTjUhDBzl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-weF6RUDCqV"
      },
      "source": [
        "### 1.2.4 Practice Problem 2: Equilibrium Temperature\n",
        "\n",
        "The [equilibrium temperature](https://en.wikipedia.org/wiki/Planetary_equilibrium_temperature) of a planet is defined as the temperature at which the power supplied by its star (due to solar radiation) is equal to the power emitted by the planet (due to blackbody radiation). The formula (in units of Kelvin) is as follows:\n",
        "\n",
        "$$ T_{\\rm eq} =  \\left( \\frac{L (1 - A_B)}{16\\sigma\\pi a^2} \\right)^{1/4}$$\n",
        "\n",
        "For the solar system, we would use $L_\\odot$, a is the distance between the planet and the Sun, $\\sigma$ is the Stefan-Boltzmann constant, and $A_B$ is the [Bond Albedo](https://en.wikipedia.org/wiki/Bond_albedo).\n",
        "\n",
        "Your task:\n",
        "1. Create a new column for the Bond albedo of each planet, taking the data from the linked wikipedia article\n",
        "2. Create a new column for the equilibrium temperature using the formula above. \n",
        "3. Create a new column for the effective/surface temperature of each planet using the values listed below. \n",
        "4. Create a scatter plot of the predicted equilibrium temperature versus the actual surface temperature. Show the 1-to-1 line ($ y=x $) using a dotted line for comparison. After reading the first linked wikipedia article, can you think of at least one reason why they may be different? (Hint: you've definitely learned about one of them in other science classes or the news)\n",
        "\n",
        "```\n",
        "Teff = [412.5, 737, 288, 215, 124.4, 95, 59.1, 59.3]\n",
        "```\n",
        "These values were taken from de Pater and Lissauer (2010).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quCOQWQmI_HI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yQ-Rr3-I_cX"
      },
      "source": [
        "## 1.3 Intermediate Pandas\n",
        "\n",
        "### 1.3.1 Boolean Indexing with DataFrames\n",
        "\n",
        "When using data, we are often only interested in a subset based on certain conditions. In pandas, we can filter DataFrames using a similar method that we used for NumPy. The key difference is that we will use the column names instead of their indices. For example, suppose we are only interested in planets that have moons.\n",
        "\n",
        "```\n",
        "df[df['N_moons'] > 0]\n",
        "```\n",
        "\n",
        "As before, we can chain multiple conditionals together. For example, let's get  the planets that have moons **and** that are further than 5 au from the Sun.\n",
        "\n",
        "```\n",
        "df[(df['N_moons'] > 0) & (df['Distance'] > 5)]\n",
        "```\n",
        "\n",
        "As a reminder, here is a list of the logical operators you can use:\n",
        "\n",
        "```\n",
        "== # equal to\n",
        "!= # not equal to\n",
        "<= # less than or equal to\n",
        "<  # less than\n",
        ">= # greater than or equal to\n",
        ">  # greater than\n",
        "\n",
        "& # logical and\n",
        "| # logical or\n",
        "~ # logical not\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gFDgRL4UEAD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KomXNChLeix"
      },
      "source": [
        "### 1.3.2 df.apply()\n",
        "\n",
        "Sometimes, it is necessary to use functions on elements of your dataframe that are not necessarily vectorized. In those cases, the best solution would simply be to create a version of the function that is compatible with vectorized quantities (i.e., a version using entirely numpy or numpy-compatible functions). There are many situations, however, where this is extremely difficult or time-consuming to accomplish, if not totally impossible. Some examples of tasks that might involve requiring these functions might include calculating very complicated quantities (e.g., elements in a row are passed as parameters to some other function for calculation) or very convoluted data cleaning.\n",
        "\n",
        "In these cases, the go-to method of dealing with this is by using `df.apply()`. For simplicity, this example will show a case where the vectorized version should be relatively straightforward. Nevertheless, it will be illustrative.\n",
        "```\n",
        "def func_to_apply(row):\n",
        "    planet = row['Name']\n",
        "    n_moons = row['N_moons']\n",
        "    if n_moons == 0:\n",
        "        return f'{planet} has no moons.'\n",
        "    elif n_moons == 1:\n",
        "        return f'{planet} has {n_moons} moon.'\n",
        "    else:\n",
        "        return f'{planet} has {n_moons} moons.'\n",
        "\n",
        "df['String Output'] = df.apply(func_to_apply, axis=1)\n",
        "```\n",
        "Verify that this function works as expected. Then, try to replicate this behavior without using `df.apply()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKA8rBnHZOzZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAzK_u7UEOi"
      },
      "source": [
        "### 1.3.3 Using Other People's Data\n",
        "\n",
        "You will likely never create your own DataFrame from scratch, instead almost all data you analyze will either be data you get from somewhere else.\n",
        "\n",
        "A common format for data is called a CSV file for comma separated values. In a CSV file, each row contains the same amount of numbers, each separated by a comma. It's possible to use other \"separators\" as well. A commonly used one is whitespace, where some number of whitespaces (whether tabs or spaces) are used to separate different values in a row.\n",
        "\n",
        "One of the main ways to read such files in Pandas is to use `pd.read_csv()`.\n",
        "\n",
        "```\n",
        "filename = 'path/to/file'\n",
        "df = pd.read_csv(filename,...)\n",
        "```\n",
        "There are multiple optional parameters worth mentioning.\n",
        "\n",
        "*   `sep`/`delimiter`: The separator to use. Defaults to `sep=','`. Another useful one is whitespace, which would be `sep='\\s+'`.\n",
        "*   `header`: Often, files will include a first row with a list of names. In this is the case, `header=0` will adopt those column names. \n",
        "*   `names`: If your file doesn't contain a header (or you don't like the names provided), you can supply your own list of names. If you pass a header in the option above, this parameter will be overwritten, so remember to use either `header` or `names`.\n",
        "*   `usecols`: If you don't want to read all the columns of a file (e.g. because of memory constraints) then you can pass a subset of columns to use. For example, if you wanted the first two and the fifth column only, then you'd use `usecols=[0,1,4]`.\n",
        "*   `comment`: It's common for files to be prepended with some number of lines telling you what the file contains and additional details. These lines will begin with some character or combination of characters so that when the computer reads them it's easy to tell which lines to ignore. One common choice is `comment='#'`.\n",
        "\n",
        "Another important thing to keep in mind: the real world is typically much messier than we would prefer. As a result, we don't always have all the information we want. So, it's common for real data to have a lot of missing values. `read_csv()` will take care of this by filling in the missing values with `np.nan`. Consider these two rows from the data you'll use in the practice problem:\n",
        "```\n",
        "324,EPIC 201427007 b,EPIC 201427007,1,1,1,Transit,2021,0.72091000,,1.500,0.134,,,,,,0,5633.00,0.94,,706.3910000\n",
        "325,EPIC 201497682 b,EPIC 201497682,1,1,1,Transit,2019,2.13174000,,0.692,0.062,,,,,,0,,,0.78,253.0260000\n",
        "```\n",
        "Ignoring what these mean for now, notice that in the middle of both rows, there are a lot of commas in a row. These correspond to five columns where either the data doesn't exist. Also, the second row is shorter because it's missing two more values than the first row. When values are missing, they will be filled in with `np.nan`.\n",
        "\n",
        "### 1.3.4 Practice Problem 3: Binaries\n",
        "\n",
        "Redo the problem from the NumPy section, but this time using Pandas. This time, the file will be a csv.\n",
        "\n",
        "Also, additional tasks:\n",
        "1. Make a scatter plot of mass vs k-type\n",
        "2. Histograms of binary total mass, mass ratio (smaller mass over larger mass), and the masses of all the individual stars.\n",
        "3. Histogram of eccentricities.\n",
        "4. Scatter plot of the total mass vs the mass ratio.\n",
        "5. Anything else you may think of."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pADNdPQ2PnSS"
      },
      "outputs": [],
      "source": [
        "# Running in Google Colab? Run this cell to download the file for this problem\n",
        "!wget https://raw.githubusercontent.com/CIERA-Northwestern/REACHpy/main/Module_3/data/binaries.csv\n",
        "\n",
        "# If you're not running in Colab, this file should be in the data directory.\n",
        "# Change the loading path of the file to include 'data/' when the file is loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdZmdDaIPq0y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GE3XgCp4ftw"
      },
      "source": [
        "### 1.3.5 Practice Problem 4: Potentially Hazardous Asteroids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMxpsa1_LwmJ"
      },
      "outputs": [],
      "source": [
        "# Running in Google Colab? Run this cell to download the file for this problem\n",
        "!wget https://raw.githubusercontent.com/CIERA-Northwestern/REACHpy/main/Module_3/data/PHA_data.csv\n",
        "\n",
        "# If you're not running in Colab, this file should be in the data directory.\n",
        "# Change the loading path of the file to include 'data/' when the file is loaded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QvK4-INOI2G"
      },
      "source": [
        "In this problem, you will look at a dataset describing Potentially Hazardous Asteroids (PHAs) which are cataloged by the Minor Planets Center, hosted at the Harvard-Smithsonian Center for Astrophysics. You will find out why these are called Potentially Hazardous.\n",
        "\n",
        "The original version of this data can be found [here](https://www.minorplanetcenter.net/data). The version supplied here has been reformatted for easier reading by `pd.read_csv()`. Note that the Center updates this data frequently, so the version here, made in early 2023, may be wildly inaccurate.\n",
        "\n",
        "The first thing to do is to open the file and look at the contents. Notice that the first line of the file contains a description of the columns. Therefore, it would be a good idea to use the keyword argument `header=0`. Similarly, the first column of data is an index, so you should use the keyword argument `index_col=0`. Finally, the last column contains a bunch of dates. In order to make sure pandas parses this data correctly, we can use the keyword argument `parse_dates=['Date of last observation']`. In the cell below, put this all together and read the file using `pd.read_csv()`. Print the dataframe and inspect it to make sure nothing is out of the ordinary. Report the total number of rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DwWlobqUXI3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBrlhqkaNJwB"
      },
      "source": [
        "Next, make two histograms, one for the pericenter and one for the apocenter of each object. Add additional lines using `plt.axvline()` representing the semimajor axis of the inner planets. Optionally, also add dashed lines around these solid lines corresponding to the pericenter and apocenter of the inner planets and Jupiter. If you can, add shading to the region in between the dashed lines using `plt.axvspan`.\n",
        "\n",
        "The documentation of `plt.axvline()` can be found [here](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.axvline.html#matplotlib.pyplot.axvline). The documentation of `plt.axvspan()` can be found [here](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.axvspan.html). Here's an example for how you'd do this for Mars. Note I am shading the region but without the dashed lines for the pericenter and apocenter. When doing this for multiple planets, it would be easier to do so with a for loop.\n",
        "```\n",
        "Mars_SMA = 1.524 # AU\n",
        "Mars_ecc = 0.0934\n",
        "\n",
        "Mars_peri = Mars_SMA*(1 - Mars_ecc)\n",
        "Mars_apo = Mars_SMA*(1 + Mars_ecc)\n",
        "\n",
        "plt.axvline(x = Mars_SMA, color='g')\n",
        "plt.axvspan(Mars_peri, Mars_apo, facecolor='g', alpha=0.5)\n",
        "```\n",
        "\n",
        "Do you notice anything potentially alarming? In order to make this a more quantitative claim, how many objects in the dataset have a pericenter smaller than Earth's semimajor axis AND an apocenter larger than Earth's semimajor axis? Repeat this for each of the inner planets and Jupiter.\n",
        "\n",
        "You should notice that some of these objects do not seem to have Earth-crossing orbits. Why do you think they're on this list?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLhdDoHmNLXW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQTyaK6CNL_w"
      },
      "source": [
        "Make an additional histogram showing the dates of last observation. Since this is datetime data, which pandas handles internally quite efficiently, you can use the method `df['Date of Last Observation'].hist()` to do this quickly. Look at the range on the x-axis. Is this concerning? \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY6d_ogbNP4S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szfgP_GqNQrS"
      },
      "source": [
        "***Optional***\n",
        "\n",
        "We can make a better version of the first two histograms in a way that's visually more intuitive. For the purposes of the code below, I'll assume you named your Dataframe `df`.\n",
        "\n",
        "First, let's reorder the rows to sort by pericenter and apocenter values in ascending order.\n",
        "```\n",
        "df = df.sort_values(by=['peri', 'apo'])\n",
        "```\n",
        "Next, since the dataset is so large, let's select only a subset of the rows to visualize. However, we still want to show the whole extent of the dataset, so choosing the first chunk of the data would not be a good option. Instead, let's choose every nth row. For this case, I'll use `n=40`, though you should feel free to play around with this number. I will make this a variable so it is easy to change later.\n",
        "```\n",
        "nth_row = 40\n",
        "df_reduced = df.iloc[::nth_row, :]\n",
        "```\n",
        "One more step. In order to make our plot look nice, let's also reset the index. Optionally, you can add the keyword argument `drop=True`. If you don't (I will not), then your new dataframe will add the old indices as a new column.\n",
        "```\n",
        "df_reduced = df_reduced.reset_index()\n",
        "```\n",
        "Now, we can get to plotting. What we will do is use the index value as the y-value so that each object gets its own line. For the x-values, we will use the semimajor axis. We will also include the extent of the orbit by plotting the pericenter and apocenter using errorbar.\n",
        "```\n",
        "xdata = df_reduced['Semimajor Axis (AU)'].values\n",
        "ydata = df_reduced.index\n",
        "xerr_low = xdata - df_reduced['peri'].values\n",
        "xerr_high = df_reduced['apo'].values - xdata\n",
        "xerr = (xerr_low, xerr_high)\n",
        "plt.errorbar(xdata, ydata, xerr = xerr, linestyle='')\n",
        "```\n",
        "As before, also added some vertical lines and shaded regions representing the inner planets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEUZkvitNSdW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
