{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3.3 | Pandas Basics\n",
    "\n",
    "So far, we have used Python lists as well as Numpy arrays to store and manipulate data, each of which have their place in a simple Python program. But there's an excellent (and very popular) Python package called Pandas that greatly facilitates handling comma separated value (CSV) files and other types of data files. The basic tool in pandas is the DataFrame, which you can think of as a large table with built-in functions to process rows and columns, read and write to many different formats on disk, and interact with other DataFrames. One key advantage of pandas over other types of data storage is that it can easily handle data of many different types, including strings and numbers.\n",
    "\n",
    "For a quick overview of Pandas' capabilities, watch the 10-minute video below from __[Wes McKinney](http://wesmckinney.com/)__, creator of the Pandas project and author of the companion book __[Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do?cmp=af-prog-books-videos-lp-na_afp_book_mckinney_cj_12307942_7040302)__.\n",
    "\n",
    "__[Here's](https://vimeo.com/59324550)__ the video!\n",
    "\n",
    "## Getting Started With Pandas\n",
    "\n",
    "In the lessons that follow, we will work through some elementary examples of how to use Pandas. First things first - is Pandas installed on your computer? If you installed the Anaconda Python package, you should already have Pandas. \n",
    "\n",
    "Try executing import pandas in the cell below - if you get an error, then you'll have to install it following instructions available on the website: http://pandas.pydata.org/pandas-docs/stable/install.html. When you're able to import the pandas module, you're ready to begin exploring the capabilities of pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to DataFrames\n",
    "\n",
    "The basic tool of pandas is the DataFrame. DataFrames are powerful data storage tools because they allow you to store many different types of data, and you can give the rows and columns names that allow you to easily access them later.\n",
    "\n",
    "Similar to importing numpy, we can import pandas with a shortened name. Usually folks use:\n",
    "> import pandas as pd\n",
    "\n",
    "Try it out in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to when we used functions from the math, NumPy, and other modules, we will now be able to access any part of the pandas package by typing \n",
    ">pd._function_name_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we'll define a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'int_col' : [1,2,6,8,-1], 'float_col' : [0.1,0.2,0.2,10.1,None], \n",
    " 'str_col' : ['a','b',None,'c','a']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines a DataFrame called 'df' that contains three columns, each with a different type of data (integers, floats, and strings), and descriptive labels (note that we've intentionally entered some values as None or NaN, which we'll return to shortly). \n",
    "\n",
    "In the cell below, you can output your DataFrame by executing the command \n",
    ">df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame is organized into a readable table with the rows and columns labeled (rows are labeled with numbers). \n",
    "\n",
    "You can also print out your DataFrame using \n",
    ">print(df) \n",
    "\n",
    "Note that executing df alone only works when it's the last command executed in your cell. \n",
    "\n",
    "Print the DataFrame in the cell below. You should notice that the output generated looks different depending on whether or not you've used print to output the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing DataFrames\n",
    "\n",
    "As with Python lists and NumPy arrays, you'll often need to access a specific entry or slice of your DataFrame. There are different techniques for indexing DataFrames, including the bracket notation [ ] and the .loc attribute. We'll show you a few different examples of how these work.\n",
    "\n",
    "A __single data__ entry can be accessed by the index of its row number (an integer) and the column label (a string) using the general format df.loc[row_indexer, column_indexer]. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note, column_indexer is a string, so it must be enclosed in quotes\n",
    "\n",
    "df.loc[0, 'str_col']          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using.loc, it's important to note that it is primarily label-based, which means that the indices you reference will be the labels of your rows and/or columns. There are other similar methods for selecting data, which we encourage you to explore in more detail in the __[pandas documentation](https://pandas.pydata.org/pandas-docs/stable/indexing.html#different-choices-for-indexing)__.\n",
    "\n",
    "### Practice\n",
    "Using the format above, see if you can perform the following tasks in the cell below:\n",
    "\n",
    "> - Print out the value of the entry in the location [4, 'int_col']<br>\n",
    "> - Change the entry in 'str_col' that contains a 'b' to a 'd'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing DataFrames\n",
    "\n",
    "Often you'll want to select certain subsets of your DataFrame—say just the float and string columns. You can slice your DataFrame using commands like these: \n",
    "\n",
    "Selects two specific columns of data by referencing their labels<br>\n",
    ">df[['float_col', 'str_col']]        \n",
    "\n",
    "Selects the first 2 rows of the data<br>\n",
    ">df[:2] \n",
    "\n",
    "Selects the first two rows of the specified columns<br>\n",
    ">df[['float_col', 'str_col']][:2]    \n",
    "\n",
    "Try out these slicing examples, and other examples you think up yourself, in the cell below until you feel comfortable with how this indexing works. Using this structure, can you select this particular slice of data and store it as subset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another very useful feature is the ability to select subsets by boolean operator (that is, you can select a subset of data that meets particular criteria). For instance, you can select all of the data with float values larger than 0.15 as follows:\n",
    " > df[df['float_col']>0.15]\n",
    " \n",
    "Try it in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this command, the inner df allows you to reference the specific column of data, and the outer (leftmost) df prints the output to screen. You can also string together multiple boolean operators for a more complicated request (e.g., either Z must be true or X and Y must be true). The operators to do this are:\n",
    "\n",
    "> | : or<br>\n",
    "> & : and<br>\n",
    "> ~ : not<br>\n",
    "\n",
    "So if we wanted to slice our DataFrame to output values greater than 0.15 and less than 0.2, we would type:\n",
    "> df[(df['float_col']>0.15) & (df['float_col'] < 0.2)]\n",
    "\n",
    "### Practice\n",
    "\n",
    "From the DataFrame, df, select all data that has float > 0.1 and int < 10, or has string = 'a'? Print this DataFrame in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working With Missing Data\n",
    "When we created our data frame, we intentionally entered None for a few of the entries. This is to simulate a common occurrence in real-world data processing—missing data. In pandas, missing refers to entries that are null or \"not present for whatever reason.\" Note that you'll see the terms None and NaN (which stands for not a number) floating around. These are different ways that Python interprets and labels null data; you can read more on the differences between None and NaN __[here](https://pandas.pydata.org/pandas-docs/stable/missing_data.html)__). Pandas has a built-in method for dealing with missing data: dropna(). One option is to drop all rows and columns that contain missing values, which can be done with the following command:\n",
    "> df2 = df.dropna()\n",
    "\n",
    "Try this out in the cell below and check that it produces the expected results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that executing df.dropna() alone will not actually change df — rather, it only returns the subset of the DataFrame with all NaNs dropped, which is why we have saved the returned DataFrame to a new one called df2. If instead you want to drop just the columns (axis=0) or just the rows (axis=1) in which either 'any' or 'all' entries are NaNs, you can variations on the statement below:\n",
    ">df2 = df.dropna(axis=1, how='all')\n",
    "\n",
    "In the cell below, use this to create another DataFrame that takes the original DataFrame (with NaNs!) and removes all columns that contain any NaNs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that this data we were working with had to do with the sizes of objects—that is, all the values should be positive. We can use the drop method to drop all the rows that meet a certain condition. In our DataFrame, let's remove all rows that contain a negative value in the 'int_col' column. We can do this as follows:\n",
    "\n",
    "> df2 = df.drop(df[df.int_col < 0].index)\n",
    "\n",
    "Let's dissect the statement, starting with the part inside the parentheses: df[df.int_col < 0] accesses each item in the 'int_col' that has a value less than 1. By putting .index at the end, the statement returns the index (the row number) of each element that fits the condition. In the full statement, df.drop(df[df.int_col < 0].index), we're selecting the rows from the DataFrame that contain negative values in the 'int_col,' and then dropping all of those rows from the DataFrame. \n",
    "\n",
    "Play around with this statement or variations of it in the cell below. It's a very useful thing to be able to do within your DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more in-depth look at how to handle missing data in pandas, take a look at the __[Working With Missing Data](https://pandas.pydata.org/pandas-docs/stable/missing_data.html)__ section in the official documentation.\n",
    "\n",
    "In the next lesson we'll cover some slightly more advanced topics in pandas, but first it's worth reiterating that there are many different ways to index data with pandas. If you're interested in exploring a bit more, check out the official documentation on __[Indexing and Slicing Data](https://pandas.pydata.org/pandas-docs/stable/indexing.html)__. \n",
    "\n",
    "## Takeaways\n",
    "\n",
    "> - DataFrames are the basic tool of pandas. DataFrames organize your data into nice, readable tables, allowing you to easily access pieces of data by the labels, or names, of your columns—much more intuitive than having to remember column numbers!<br>\n",
    "> - You can create DataFrames manually, or load them from file using one of the many file-reading functions that work will all different types of data files<br>\n",
    "> - Pandas has lots of built-in functionality to allow you to drop missing data (i.e., df2.dropna()) and select a specific slice of data to work with (e.g., df[df['float_col']>0.15])<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
