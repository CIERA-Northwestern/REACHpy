{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3.4 | Exploring More Complex Data Files With Pandas\n",
    "\n",
    "## Reading and Writing Data Files With Pandas\n",
    "\n",
    "We typically want to read in and write out our data from/to data files. Pandas has functions for working with many different types of data files, including hierarchical data formats (HDF, which is a binary file format), CSV files, and Excel files, among others. Let's bring back our DataFrame (df) from the previous lesson, and let's write it out to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'int_col' : [1,2,6,8,-1], 'float_col' : [0.1,0.2,0.2,10.1,None],\n",
    "    'str_col' : ['a','b',None,'c','a']})\n",
    "outfile = './exampleframe.csv'\n",
    "df.to_csv(outfile,header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the to_csv method to output to other formats, for example using tabs or other characters as a delimiter between your data entries, instead of commas. Try typing \n",
    "> df.to_csv?<br>\n",
    "\n",
    "in the cell below to see what options are available for this method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read the file back in as follows:\n",
    "\n",
    ">infile = 'exampleframe.csv' <br>\n",
    ">df = pd.read_csv(infile) <br>\n",
    "\n",
    "Do this in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you want to read in another type of file? On the cell below, type in pd.read_ and hit tab to get a list of all the read functions available in pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more in-depth overview, refer to __[this](http://pandas.pydata.org/pandas-docs/version/0.20/io.html)__ section of the official documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Manipulating DataFrames\n",
    "\n",
    "Let's learn a few more advanced techniques for working with pandas DataFrames.\n",
    "\n",
    "### Basic Data Analysis\n",
    "\n",
    "In Section 3.3, you learned how to drop missing data. Alternatively, you can fill it in with some guess for what the value should be. For example, run the following lines of code in the cell below to compute the mean of the values in the 'float_col', and replace the NaN with that value (you could similarly use sum, max, etc.):\n",
    "\n",
    "> This command creates a copy of the original DataFrame<br>\n",
    "> df2 = df.copy()<br>\n",
    "> mean = df2['float_col'].mean()<br>\n",
    "> df2['float_col'].fillna(mean,inplace=True) <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what happens if you don't use inplace=True in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just saw one example of the built-in stats tools that are part of pandas, which save you the effort of writing your own code to perform simple tasks, such as calculating the mean of your data. One of the nice things about pandas is that it automatically recognizes the columns to which the stats functions can apply. That is, it doesn't try to calculate the mean of strings.\n",
    "\n",
    "For a nice summary of your DataFrame, type: \n",
    "> df.describe()<br>\n",
    "\n",
    "You'll see that this provides you with many useful quantities regarding your dataset, but it knows not to compute the values for the string column.\n",
    "\n",
    "## Manipulating DataFrames\n",
    "\n",
    "With DataFrames it's easy to do vectorized operations, which means that the computer can automatically interpret that you'd like to perform the operation to/with all elements of a column. For example, map applies the function to all elements of the column. In the cell below, try out these next two lines of code:\n",
    "\n",
    ">df['str_col'].dropna(inplace=True)<br>\n",
    ">df['str_col'].map(lambda x: 'newvalue_'+x)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line drops all of the entries in the strings column that have no data, and the second line applies a function to each of the remaining entries. (In Python, the lambda keyword provides a shortcut for writing anonymous (unnamed) functions. To see why you would you want to do that over defining a function the usual way, i.e., using def and return, take a look at this __[post](https://dbader.org/blog/python-lambda-functions)__.\n",
    "\n",
    "How would you modify this function if you wanted each entry in the strings column to go from 'x' to 'xx' (i.e., a -> aa)? Try it out in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous examples, you applied a function to each item in a column. In contrast, the apply method uses each entry in the column, but applies a function to the column as a whole. For instance (assuming you've loaded the package numpy as np), you can calculate the sum of an entire column via \n",
    "> df[['int_col','float_col']].apply(np.sum)\n",
    "\n",
    "Try this out in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we would like to apply a function that we have written ourselves to each entry of a data frame. You might want to define a function with the following syntax, which will act on columns in different ways depending on their data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(x):\n",
    " if type(x) is str:\n",
    "      return 'my_string_function_' + x\n",
    " elif x:\n",
    "      return np.sqrt(np.abs(x))\n",
    " else:\n",
    "      return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can apply this function to each element in your DataFrame with:\n",
    "> df.applymap(my_function)\n",
    "\n",
    "Try it out in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding Your DataFrames\n",
    "\n",
    "Sometimes you'll need to expand your DataFrame by adding additional columns, or by joining together multiple DataFrames. Let's see a few of the ways that this can be done.\n",
    "\n",
    "First, let's define a new DataFrame with two columns: The first column, labeled \"A,\" should contain the integers [1,2], and the second one, labeled \"B,\" should contain the floats [1.2,1.3]. \n",
    "\n",
    "Define this new DataFrame in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, say we want to add a few columns of data to this DataFrame. We can add a new column that is a function of the existing columns, or one with completely independent data, as shown below:\n",
    "> df[\"C\"] = df[\"A\"]+df[\"B\"]<br>\n",
    "> df[\"D\"] = df[\"A\"]*3<br>\n",
    "> df[\"E\"] = np.sqrt(df[\"A\"])<br>\n",
    "\n",
    "Try it below! After adding all of these columns, take a look at the your updated DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A final piece of often-useful data manipulation that is made easy by Pandas is joining and merging data sets. Let's redefine our original test DataFrame, in case it's been modified since you last used it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'int_col' : [1,2,6,8,-1], \n",
    "                   'float_col' : [0.1, 0.2,0.3,10.1,4.0], \n",
    "                   'str_col' : ['a','b','b','c','a']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a different data frame that contains different information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "other =  pd.DataFrame({'str_col' : ['a','b'], 'some_val' : [1, 2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can merge these two data frames using a few different methods. The inner merge is executed like this:\n",
    ">pd.merge(df,other,on='str_col',how='inner')\n",
    "\n",
    "Try merging the two DataFrames in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the resulting DataFrame and see if you can figure out what's happening. Learning the different actions of the different merger types is best accomplished by simply playing with the options. The other types of merger are outer, left, and right. Try all of these options, as well as changing the name of the 'on' option, in the cell below to learn what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more comprehensive overview of joining and merging DataFrames, check out this __[section](https://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging)__ of the official pandas documentation.\n",
    "\n",
    "## Takeaways \n",
    "\n",
    "> - You can use the many built-in read functions to load data from many different file formats (e.g., read_table, read_csv, read_hdf) <br>\n",
    "> - The very useful describe function provides some basic statistics on your numerical data (and it's intelligent enough to leave out any string columns when doing this). It's as simple as typeing df.describe()!<br>\n",
    "> - Manipulate your DataFrame by performing simple arithmetic operations on your columns (e.g., df[\"E\"] = np.sqrt(df[\"A\"])), or apply built-in or user-defined functions by using apply or applymap <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
