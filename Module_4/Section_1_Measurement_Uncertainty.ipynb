{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDfdlYPrpm6I"
      },
      "source": [
        "# Section 1 Measurement Uncertainty and Error Propagation"
      ],
      "id": "RDfdlYPrpm6I"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkHAEjOVpm6P"
      },
      "source": [
        "\"All measurements, however careful and scientific, are subject to some uncertainties.\" \n",
        "-J.R Taylor in *An Introduction to Error Analysis*"
      ],
      "id": "LkHAEjOVpm6P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O5Y8tjfpm6P"
      },
      "source": [
        "## 1.1 Inevitability of Uncertainty"
      ],
      "id": "-O5Y8tjfpm6P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH_ZwovWpm6Q"
      },
      "source": [
        "Every time we conduct a measurement, the number we obtain comes with an associated uncertainty. This uncertainty quantifies the precision of the experiment as well as our degree of ignorance of the targeted number.\n",
        "\n",
        "\n",
        "![Ruler](https://raw.githubusercontent.com/CIERA-Northwestern/REACHpy/main/Module_4/images/ruler.png)\n",
        "\n",
        "For example, every time we use a tape measure, graduated in eigths of an inch, we may be able to tell that say, the length of a window, is between 54 1/8'' and 54 2/8'' --or between 54.175 in and 54.25 in. But we are unable to precisely tell if the length is 54.18 in or 54.24 in. Moreover, if the tape measure *appears* to exactly fall at the 54 1/8''  mark, we are not able to tell accurately if the length of the window is 54.175 or 54.1750001. This is what we refer to as **uncertainty** as is inherent to all experimental measurements."
      ],
      "id": "AH_ZwovWpm6Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5kkOdRPpm6Q"
      },
      "source": [
        "## 1.2 Types of error\n",
        "\n",
        "There are two types of error: **systematic** and **random** (some people like to add a third type: human blunders).\n",
        "\n",
        "A **systematic uncertainty** is something that causes a measurement to always be consistently different from the actual value (a bias). Systematic uncertainties can be difficult to forsee, but once identified, they are easy to predict or correct for. In astronomy, systematic uncertainties can be either due to **instrumental effects** and **physical effects**. For instance a poorly calibrated telescope will systematically measure stellar magntitudes in a biased way (an instrumental effect). In addition, \n",
        "\n",
        "\n",
        "\n",
        "A **random uncertainty**  are things that cause a value to change unpredictably each time your measure it. Random uncertainties are nearly impossible to eliminate, but can be reduced with increased sample size. In astronomy, random uncertainties are often referred to as **noise**, and can be either due to **instrumental effects** and/or **physical effects**. For instance, instruments can contribute **thermal noise** (random fluctuations that moves electrons around in the detector) and **readout noise** (errors in the way currents are measured). But also, stars can vary in stochastic ways, which translates into **stellar shot noise**, which is ultimately physical in origin.\n"
      ],
      "id": "n5kkOdRPpm6Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lBbR9Iypm6R"
      },
      "source": [
        "### 1.2.1 Precision vs Accuracy\n",
        "When taking and analyzing measurements, one must distinguish between **precise** measurements and **accurate** measurements. **Precision** is the ability of a measurement to be reproduced consistently. On the other hand, **accuracy** is the degree of closeness of measurements of a quantity to that quantityâ€™s actual (true) value.\n",
        "A lack of accuracy is usally associated to **systematic errors** (or bias), while a lack of precision is usually associated to **random errors**"
      ],
      "id": "_lBbR9Iypm6R"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KffNQBJmpm6R"
      },
      "source": [
        "![Precision versus accuracy](https://raw.githubusercontent.com/CIERA-Northwestern/REACHpy/main/Module_4/images/precision_accuracy.png)"
      ],
      "id": "KffNQBJmpm6R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XM5dnMCtpm6R"
      },
      "outputs": [],
      "source": [
        "# If you are working on Google colab, you will need to download the datasets\n",
        "!wget https://raw.githubusercontent.com/CIERA-Northwestern/REACHpy/main/Module_4/data/measurement_data1.txt\n",
        "!wget https://raw.githubusercontent.com/CIERA-Northwestern/REACHpy/main/Module_4/data/measurement_data2.txt"
      ],
      "id": "XM5dnMCtpm6R"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zynDEwHpm6S"
      },
      "source": [
        "### EXERCISE\n",
        "Consider the two datasets `measurement_data1.txt` and `measurement_data2.txt`. Read them using numpy.loadtxt(). Each set consists of repeated instances of the same measurment, but the two sets corresponds to two different instruments. Both instruments aim to measure the same number, whose true value is $X=5$. All fluctuations are due to random experimental noise. Which experiment is more accurate? Which experiment is more precise?\n"
      ],
      "id": "8zynDEwHpm6S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtJ7v4y0pm6T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#enter code here\n",
        "\n"
      ],
      "id": "JtJ7v4y0pm6T"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ5dqdI9pm6T"
      },
      "source": [
        "Make histograms of each dataset. Assume you can represent the histograms with Gaussian/Normal/bell curves, i.e.\n",
        "\n",
        "\\begin{equation}\n",
        "y = A \\, e^{\\frac{(x - \\bar{x})^2}{2 \\sigma^2}},\n",
        "\\end{equation}\n",
        "\n",
        "where $\\bar{x}$ is the mean and $\\sigma$ is the standard deviation. How can you best guess/estimate the parameters of the Normal curves? Plot the smooth curves over the histograms."
      ],
      "id": "eZ5dqdI9pm6T"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuoHBtVCpm6T"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#enter code here"
      ],
      "id": "JuoHBtVCpm6T"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sNJ_LrZpm6U"
      },
      "source": [
        "## 1.3 Reporting and Displaying Uncertainty in a Graph: Error bars\n",
        "\n",
        " Uncertainty is often reported as\n",
        "\n",
        "\\begin{equation}\n",
        "(\\rm{ measured}\\,A)=\\bar{A}\\pm\\delta A\n",
        "\\end{equation}\n",
        "\n",
        "where \\\\(\\bar{A}\\\\) is the \"best estimate\" (or *expectation value* in more technical terms) of the measurement, and \n",
        "where \\\\(\\delta{A}\\\\) quantifies the degree of uncertainty. When expressed graphically \\\\(\\delta A\\\\) is often referred to as the **error bar**. In matplotlib, errorbars can be depicted using [plt.errorbar()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.errorbar.html)\n",
        "\n",
        "### EXERCISE\n",
        "\n",
        "Use plt.errorbar() and the two datasets from above to recreate the following plot. \n",
        "Then report each measurement in the format \\\\(\\bar{X}\\pm\\delta X\\\\). How did you compute \\\\(\\bar{X}\\\\) and \\\\(\\delta X\\\\)? And why did you do it that way?\n",
        "![Experimental data](https://raw.githubusercontent.com/CIERA-Northwestern/REACHpy/main/Module_4/images/experimental_data.png)"
      ],
      "id": "6sNJ_LrZpm6U"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhCvs3gWpm6U"
      },
      "outputs": [],
      "source": [
        "# enter code here"
      ],
      "id": "xhCvs3gWpm6U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-spmobo2pm6U"
      },
      "source": [
        "Despite being less precise, Experiment 1 is **consistent** with the **prior knowledge** that \\\\(X=5\\\\). By contrast, Experiment 2, a more precise one, is \"at tension\" with Experiment 1 *and* our prior knowledge. Rouughly speaking, if the two data points have different best estimates **and** their error bars do not overlap, we talk about inconsistent results (they cannot both be correct!) or of a \"tension.\" This inconsistency is something we see in Astronomy today, in a phenomenon known as the Hubble tension, where different measurements give inconsistent results for the Hubble constant:\n",
        "\n",
        "![H0 over time](https://raw.githubusercontent.com/CIERA-Northwestern/REACHpy/main/Module_4/images/H0_vs_year-600px.jpg)"
      ],
      "id": "-spmobo2pm6U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeZQBNVHpm6V"
      },
      "source": [
        "### EXERCISE\n",
        "Generate your own dataset assuming the fluctuations are given by a Normal distribution, e.g.,\n",
        "\n",
        "```python\n",
        "N=50\n",
        "mu, s = 5, 10\n",
        "newdata = np.random.randn(N) * s + mu\n",
        "```\n",
        "Assume that in subsequent years you are able to (1) carry out more measurements (increase <code>N</code>) and (2) reduce the instrumental fluctuation <code>s</code>. Then plot the measurement (best estimate and uncertainty) as a function of time (say, from 2021 to 2030 with an experiment every two years). What happens to \\\\(\\bar{X}\\\\) and \\\\(\\delta X\\\\)? Why is it not always the case that \\\\(\\bar{X}=\\mu=5\\\\)?\n"
      ],
      "id": "PeZQBNVHpm6V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KSTXHBZpm6V"
      },
      "outputs": [],
      "source": [
        "#enter code here"
      ],
      "id": "5KSTXHBZpm6V"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEV9A7AApm6W"
      },
      "source": [
        "### EXERCISE: Error bars in Kepler data\n",
        "\n",
        "Using pandas, you can download directly from an online database into a dataframe, e.g.,\n",
        "```python\n",
        "import pandas as pd\n",
        "kepler_url=\"https://exoplanetarchive.ipac.caltech.edu/cgi-bin/nstedAPI/nph-nstedAPI?table=cumulative&where=koi_disposition+like+'CONFIRMED'&format=csv\"\n",
        "df=pd.read_csv(kepler_url) \n",
        "\n",
        "```\n",
        "Download these data into your own dataframe and then Confirm that you have read-in a Pandas dataframe with the following column names\n",
        "```python\n",
        "print(df.columns)\n",
        "Index(['kepid', 'kepoi_name', 'kepler_name', 'koi_disposition',\n",
        "       'koi_pdisposition', 'koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss',\n",
        "       'koi_fpflag_co', 'koi_fpflag_ec', 'koi_period', 'koi_period_err1',\n",
        "       'koi_period_err2', 'koi_time0bk', 'koi_time0bk_err1',\n",
        "       'koi_time0bk_err2', 'koi_impact', 'koi_impact_err1', 'koi_impact_err2',\n",
        "       'koi_duration', 'koi_duration_err1', 'koi_duration_err2', 'koi_depth',\n",
        "       'koi_depth_err1', 'koi_depth_err2', 'koi_prad', 'koi_prad_err1',\n",
        "       'koi_prad_err2', 'koi_teq', 'koi_teq_err1', 'koi_teq_err2', 'koi_insol',\n",
        "       'koi_insol_err1', 'koi_insol_err2', 'koi_model_snr', 'koi_tce_plnt_num',\n",
        "       'koi_tce_delivname', 'koi_steff', 'koi_steff_err1', 'koi_steff_err2',\n",
        "       'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2', 'koi_srad',\n",
        "       'koi_srad_err1', 'koi_srad_err2', 'ra_str', 'dec_str', 'koi_kepmag',\n",
        "       'koi_kepmag_err'],\n",
        "      dtype='object')\n",
        "\n",
        "```\n",
        "The column containing planet radius is  <code>'koi_prad'</code> and the column containing orbital periods is <code>'koi_period'</code>. Note that there is an **upper error bar** <code>'koi_prad_err1'</code> and a **lower error bar** <code>'koi_prad_err2'</code> for the planet radius, and similarly for the orbital period.\n",
        "\n",
        "Using what you have learned about matplotlib and pandas, recreate the following plot\n",
        "![Period radius relationship](https://raw.githubusercontent.com/CIERA-Northwestern/REACHpy/main/Module_4/images/kepler_period-radius.png)"
      ],
      "id": "hEV9A7AApm6W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mlmoovpjpm6W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#enter code here"
      ],
      "id": "Mlmoovpjpm6W"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Anj3Vm7pm6W"
      },
      "source": [
        "### EXERCISE\n",
        "What is the average precision (i.e., uncertainty-divided-by-measurement in percentage notation) for planet radius?\n",
        "Are there any planets whose radii are measured to a better precision than 1%? What are their names?"
      ],
      "id": "5Anj3Vm7pm6W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K58EYxoYpm6W"
      },
      "outputs": [],
      "source": [
        "# enter your code here"
      ],
      "id": "K58EYxoYpm6W"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njj9NUCTpm6X"
      },
      "source": [
        "### EXERCISE\n",
        "Use what you have learned about **data slicing** in pandas. For example, \n",
        "```python\n",
        "index = df['koi_srad'] > 4\n",
        "df[index]\n",
        "```\n",
        "will return a dataframe in which the stellar radius column <code>'koi_srad'</code> is always greater than \\\\(R_\\odot\\\\). \n",
        "\n",
        "Use slicing to graph only planets that have radii larger than 7\\\\( R_{\\oplus}\\\\) and orbital periods shorter than 10 d. \n",
        "How many are there? What can you say about the properties and characteristics of such planets?"
      ],
      "id": "njj9NUCTpm6X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXxY4OVEpm6X"
      },
      "outputs": [],
      "source": [
        "# enter your code here"
      ],
      "id": "gXxY4OVEpm6X"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU5x_MUjpm6X"
      },
      "source": [
        "### EXERCISE\n",
        "Use data slicing to find out how many planets orbits stars with temperatures in the range \\\\([5400 \\rm{K},5700 \\rm{K}]\\\\) (use the label 'koi_steff' in the data frame)? How about in the ranges \\\\([5700 \\rm{K},6000 \\rm{K}]\\\\)\n",
        "and \\\\([6000 \\rm{K},6300 \\rm{K}]\\\\)? What is the mean precision in planetary radius for each of these intervals? Can you conclude anything from these values? Offer hypothesis and a counterpoint to your hypothesis."
      ],
      "id": "CU5x_MUjpm6X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAU7XtGPpm6X"
      },
      "outputs": [],
      "source": [
        "#enter your code here"
      ],
      "id": "zAU7XtGPpm6X"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZaqn2ccpm6X"
      },
      "source": [
        "\n",
        "Now, **how were all those planet radii measured???**\n",
        "\n",
        "Nobody went toward each planetary system and used a ruler to measure each planet's radius. So how were all these radii measured? More importantly for our current purposes: how are those radius uncertainties calculated if no \"ruler\" was used?\n",
        "\n",
        "These radii and their corresponding errors are derived from **fitting a model**. Below we show the actual data from Kepler (a so-called *light curve*) which has uncertainty bars due to instrumental and physical errors. In addition, we show **the model light curve** corresponding to a planet blocking the light from the star. The model depends on planet radius, and thus a \"best fit model\" can be matched to the data.\n",
        "\n",
        "![K2-28 transit light curve](https://raw.githubusercontent.com/CIERA-Northwestern/REACHpy/main/Module_4/images/K2-28_transit_light_curve.png)\n",
        "\n",
        "Since the data have errors/uncertainties, it is not possible to determine the planet radius with arbitrary precision, and thus the planet radius itself is known within an interval of confidence $R_{\\rm p}=\\bar{R}_{\\rm p}\\pm \\delta R_{\\rm p}$. Thus, errors from the **measured data** (the light curve) are **propagated** to the errors in the **inferred quantity** (the planet radius). The details of how to derive uncertainties in inferred quantities during model fitting will be covered in a different section.\n"
      ],
      "id": "yZaqn2ccpm6X"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV-scmUXpm6Y"
      },
      "source": [
        "## 1.4 Error propagation\n",
        "If the relation between measured data and inferred quantities is simple, **and** the different measured data can be considered independent variables, we can obtain the uncertainties in the inferred quantity carrying out an analysis technique known as **error propagation**.\n",
        "\n",
        "Multiple textbooks cover the concept of *error propagation*. In some cases, error propagation can be carried out via simple operations. For instance, consider a **dependent** quantity \\\\(U\\\\), such that \\\\(U\\\\) depends on other measurable quantities \\\\(A,B,C,...\\\\) in the form of a function\n",
        "\\begin{equation}\n",
        "U=f(A,B,C,...)~.\n",
        "\\end{equation}\n",
        "\n",
        "Then,  to find the best estimate for \\\\(U\\\\), the best estimate of each measured variable is substituted into the equation for \n",
        "\\begin{equation}\n",
        "\\bar{U}=f(\\bar{A},\\bar{B},\\bar{C},...)~.\n",
        "\\end{equation}\n",
        "\n",
        "If the errors for \\\\(A, B, C\\\\), . . . are independent, random, and sufficiently small, it can be shown\n",
        "that the uncertainty for \\\\(U\\\\) is given by\n",
        "\\begin{equation}\n",
        "\\delta{U}=\\sqrt{\\left(\\frac{\\partial U}{\\partial A}\\right)^2\\delta A^2\n",
        "+\\left(\\frac{\\partial U}{\\partial B}\\right)^2\\delta B^2\n",
        "+\\left(\\frac{\\partial U}{\\partial C}\\right)^2\\delta C^2\n",
        "+...\n",
        "}\n",
        "\\end{equation}\n",
        "\n",
        "For instance, for the sum of variables,\n",
        "\n",
        "\\begin{equation}\n",
        "U=A+B~,\\;\\;\\;\\;\\;\n",
        "\\delta U =\\sqrt{\\delta A^2+ \\delta B^2}\n",
        "\\end{equation}\n",
        "\n",
        "Or, for the product\n",
        "\n",
        "\\begin{equation}\n",
        "U=AB~,\\;\\;\\;\\;\\;\n",
        "\\delta U =U\\sqrt{\\left(\\frac{\\delta A}{A}\\right)^2+ \\left(\\frac{\\delta B}{B}\\right)^2}\n",
        "\\end{equation}\n",
        "\n"
      ],
      "id": "mV-scmUXpm6Y"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eWkSVgVpm6Y"
      },
      "source": [
        "### EXERCISE\n",
        "If know a star's  stellar radius \\\\(R_\\star\\\\)  and its effective temperature \\\\(T_{\\rm eff}\\\\), we can in principle compute its luminosity \\\\(L_\\star\\\\)the since we know that\n",
        "\\begin{equation}\n",
        "L_\\star =4\\pi\\sigma R_\\star^2 T_{\\rm eff}^4\n",
        "=L_\\odot \\left(\\frac{R_\\star}{R_\\odot}\\right)^2 \\left(\\frac{T_{\\rm eff}}{T_{{\\rm eff},\\odot}}\\right)^4\n",
        "\\end{equation}\n",
        "\n",
        "From what we learned above, we can estimate the uncertainty in luminosity as\n",
        "\n",
        "\\begin{equation}\n",
        "\\delta L_\\star=L_\\star\\sqrt{\n",
        "4\\frac{\\delta R_\\star^2}{R_\\star^2}+\n",
        "16\\frac{\\delta T_{\\rm eff}^2}{T_{\\rm eff}^2}\n",
        "}\n",
        "\\end{equation}\n",
        "\n",
        "Using the columns <code>'koi_srad'</code>,  <code>'koi_steff'</code> and their respective uncertainties, estimate the luminosity for the first ~10 entries of the data frame. You may assume\n",
        "\\\\(T_{{\\rm eff},\\odot}=5777{\\rm K}\\\\) and\n",
        "use the following code snippet:\n",
        "```python\n",
        "\n",
        "for index,row in df.iterrows(): \n",
        "    R = row['koi_srad']\n",
        "    Teff = row['koi_steff']\n",
        "    deltaR = \n",
        "    deltaTeff =\n",
        "    L =\n",
        "    deltaL =\n",
        "```\n"
      ],
      "id": "9eWkSVgVpm6Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A7RggCVpm6Y"
      },
      "outputs": [],
      "source": [
        "# enter your code here"
      ],
      "id": "7A7RggCVpm6Y"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE7S-Hyepm6Z"
      },
      "source": [
        "### 1.4.1 Error propagation from Monte Carlo Sampling\n",
        "An alternative method to using the formulas above is to \"recreate\" the uncertainties in the measurement by sampling from a model distribution. For example, to create 100 random instances of the planet radius, assuming a Normal distribution,\n",
        "\n",
        "```python\n",
        "N=100\n",
        "for index,row in df.iterrows(): \n",
        "    mu, s = row['koi_prad'], 0.5*(np.abs(row['koi_prad_err1'])+np.abs(row['koi_prad_err2']))\n",
        "    resampled_radius = np.random.randn(N) * s + mu\n",
        "```"
      ],
      "id": "eE7S-Hyepm6Z"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehJSJTzFpm6Z"
      },
      "source": [
        "### EXERCISE\n",
        "Use the resampling method above to loop over the dataframe and resample the stellar radius and stellar effective temperature, and from these, compute the stellar luminosity <code>N</code> times. From this resampled set of luminosities, provide a **best estimate** and an **uncertainty** and save these two numbers for each entry creating two arrays of size  <code>N</code>. You may wish to add these two new arrays as new columns in the dataframe.\n",
        "\n",
        "```python\n",
        "L = []\n",
        "deltaL = []\n",
        "N=100\n",
        "for index,row in df.iterrows(): \n",
        "    ...\n",
        "    resampled_sradius = \n",
        "    resampled_Teff = \n",
        "    resampled_L = \n",
        "    L.append(...)\n",
        "    deltaL.append(...)\n",
        "    \n",
        "```\n"
      ],
      "id": "ehJSJTzFpm6Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOAHRaLvpm6Z"
      },
      "outputs": [],
      "source": [
        "# enter your code here"
      ],
      "id": "OOAHRaLvpm6Z"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTDtEtBupm6a"
      },
      "source": [
        "### EXERCISE\n",
        "Try to recreate the period-radius plot above, but replacing planet radius with your derived luminosity (including the error bars). Do you see any trends?"
      ],
      "id": "fTDtEtBupm6a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akk9Ghvrpm6b"
      },
      "outputs": [],
      "source": [
        "# enter your code here"
      ],
      "id": "akk9Ghvrpm6b"
    }
  ],
  "metadata": {
    "colab": {
      "name": "MeasurementUncertainty.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}