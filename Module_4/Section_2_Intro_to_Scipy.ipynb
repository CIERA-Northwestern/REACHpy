{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wQB9HSUp5Jf"
      },
      "source": [
        "# Section 2 SciPy: Python tools for science\n",
        "*Monica Rizzo, 2021*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buFShgdkp5Jk"
      },
      "source": [
        "SciPy is one of many Python packages that has a lot of useful tools for data analysis. Specifically, it was designed with STEM applications in mind, so most of its modules are for performing mathematical operations.  In this notebook we're going to be going over some of the functions in Scipy you can use to fit and model data. This is not at all an exhaustive tutorial though, so feel free to explore all of the different uses of SciPy on your own.\n",
        "\n",
        "First things first, lets import all of the important stuff."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn4CyHgwp5Jl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.optimize import brentq\n",
        "\n",
        "from scipy.integrate import quad\n",
        "from scipy.misc import derivative\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#this makes the plot labels bigger (looks nicer)\n",
        "plt.rcParams.update({'font.size': 18})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZSmngY1p5Jn"
      },
      "source": [
        "## 2.1 Functions: A Review\n",
        "\n",
        "Way back in Module 2, you learned about Python functions, and went over how to define your own. In order to use some of SciPy's curve fitting tools, you will need to define functions for it to fit. So let's briefly review what goes into building a Python function, and how you can turn a math function into a Python function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxVSaYIvp5Jn"
      },
      "source": [
        "A quadratic function has the form:\n",
        "\n",
        "\\begin{equation*}f(x) = y = a x^2 + b x + c \\end{equation*}\n",
        "    \n",
        "As a Python function, we would write this as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2ZWazdYp5Jo"
      },
      "outputs": [],
      "source": [
        "def function(x, a, b, c):\n",
        "    \n",
        "    y = a * x**2 + b * x + c\n",
        "    \n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04AzDKgAp5Jo"
      },
      "source": [
        "In math classes, you've probably talked about functions in terms of independent and dependent variables. In this example, we could call 'x' the independent variable and 'y' the dependent variable. Then 'a', 'b', and 'c' are what we would call **parameters** - these are values you can adjust to change the shape of the function. In this notebook, we'll be looking at how you can tune the parameters of a user-defined function to reproduce the shape of an arbitrary data set.\n",
        "\n",
        "\n",
        "You can write a Python function to accept any number of parameters and variables, but for the following examples, we'll be looking at cases where there is only one set of independent variables (a single array) and multiple parameters. Keep in mind that the order of variables and parameters matters - when you define your function, write it to take **variables first, then parameters**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vvu-AHSIp5Jo"
      },
      "source": [
        "## 2.2 Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp5d4jeap5Jp"
      },
      "source": [
        "There are a lot of things you can do with data. Often times, we will want to either 1) see how well data agrees with a given model or 2) without assuming anything, see what sort of model agrees the best with some data.\n",
        "One way to test this is by using regression techniques. \"Regression\" is just the math word for fitting data to a certain function. You may have done something similar to this before with Excel, or by hand using graph paper. \n",
        "\n",
        "Lucky for us, SciPy can quickly and easily fit things for you. First, lets generate some data that follows a known function - a straight line.\n",
        "1. **Using numpy, create an array of n equally spaced x values within some range - doesn't really matter what range**\n",
        "2. **Then choose two values for the slope m and y-intercept b**\n",
        "3. **Finally, create a numpy array of y values which follows the equation for a line**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fpva-SB5p5Jp"
      },
      "outputs": [],
      "source": [
        "#create a numpy array of x values \n",
        "#keep n relatively small (~10-20)\n",
        "x_values = #complete\n",
        "\n",
        "\n",
        "#make an array of y values that follow the equation of a line\n",
        "y_values = #complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCqNpXEWp5Jq"
      },
      "source": [
        "Now let's plot the data to see what it looks like (always a good first step).\n",
        "1. **Make a scatter plot of the x and y values you created above**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeWPXbHCp5Jq"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "#complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snn-iEzdp5Jq"
      },
      "source": [
        "The Scipy function we are going to use to do the fitting is called *curve_fit*. Given a user-defined Python function that describes the fit (in this case a line), *curve_fit* will attempt to find the best fitting parameters for some input data. So, in this case, we want to create a function that returns y-values corresponding to a line, and takes x-values and 2 free parameters: the slope and the y intercept. Then, we want to hand *curve_fit* that fit-function, the x data, and the y data, and it's going to tell us what it thinks the best fitting parameters are, along with the uncertainties on those parameters (which we're not going to worry about right now).\n",
        "\n",
        "1. **Define a function which takes as inputs x, m, and b, and returns the y values corresponding to a line**\n",
        "2. **Pass *curve_fit* the name of your fit function, your x data, and your y data (see documentation here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html)**\n",
        "3. **Print the result of *curve_fit* (note: result should be a 2 element array. The values are in the same order as the parameters of your fit-function)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YaTgij4p5Jr"
      },
      "outputs": [],
      "source": [
        "def fit_function():\n",
        "    #complete\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wzuzghpp5Jr"
      },
      "outputs": [],
      "source": [
        "result, cov = curve_fit(#complete\n",
        "\n",
        "#print the result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wsPh4fpp5Jr"
      },
      "source": [
        "Nice.\n",
        "\n",
        "![Alt Text](https://media.giphy.com/media/XreQmk7ETCak0/giphy.gif)\n",
        "\n",
        "Now let's look at a more realistic example. In real life, data is noisy and usually has some associated uncertainty. Lets add a little bit of noise to our existing data, and assign some uncertainty.\n",
        "\n",
        "1. **Generate random values using *np.random.normal*, and add those values to your array of y values (documentation here: https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)**\n",
        "2. **Create an array - which will be your y-error - of length n where all of the values are the same as what you set the 'scale' option to in *np.random.normal***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbFGBb09p5Jr"
      },
      "outputs": [],
      "source": [
        "#generate some random numbers drawn from a bell curve\n",
        "#use 'size' option to specify number of points and 'scale' option to specify noise level\n",
        "y_noise = \n",
        "\n",
        "#array of y values plus noise\n",
        "y_noisy_values = \n",
        "\n",
        "#array uncertainty values\n",
        "#hint: use np.ones()\n",
        "y_error = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkHao7-gp5Jr"
      },
      "source": [
        "Now, let's plot the data again. In order to plot the errors, instead of using the 'plot' function, use 'errorbar': https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.errorbar.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px_y4gedp5Jr"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "#try using fmt='o' and markersize=6.0\n",
        "plt.errorbar(#complete\n",
        "#complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-5FJvWxp5Js"
      },
      "source": [
        "Not so pretty anymore, but maybe still looks like a line? The larger you make the 'scale' option in *np.random.normal*, the more noisy the data will look. You can try upping the value to make the data noisier if it's not significantly noisy already. Then, let's see what SciPy thinks. \n",
        "\n",
        "1. **Using the same syntax as before, pass *curve_fit* the same fit-function and x data, your noisy y data, and also the uncertainty on your y values - this can be done using the 'sigma' option.**\n",
        "2. **As before, print the result**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XM14JWbop5Js"
      },
      "outputs": [],
      "source": [
        "#use curve fit to find the fit parameters for your noisy data\n",
        "result, cov = curve_fit(#complete\n",
        "\n",
        "#print the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEmlERphp5Js"
      },
      "source": [
        "You may find that this answer is pretty different from the actual values of the parameters. We can plot what the fit looks like over our data to visually assess how bad/good it is. \n",
        "\n",
        "1. **Create a numpy array of test x values that has a slightly larger range, and more points than your original x values**\n",
        "2. **Pass this array, along with the best fit m and b values, to your fit function, and store the result as a separate array**\n",
        "3. **Copy the cell you used to plot the data with errorbars, and add a line to plot the new x values and predicted y values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oX_D-BZ7p5Js"
      },
      "outputs": [],
      "source": [
        "#array of x test values\n",
        "x_test_values = #complete\n",
        "\n",
        "#array of y test values \n",
        "y_test_values = fit_function(#complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEIGOLgep5Js"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "#complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT_JXtXLp5Jt"
      },
      "source": [
        "Keep in mind that these answers are just predictions - they also have some uncertainty to them. The other thing that *curve_fit* returns - which we're calling *cov* - describes the uncertainites on the fit parameters. Let's see what those look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFSw4yinp5Jt"
      },
      "outputs": [],
      "source": [
        "#cov is a matrix, and we only want the diagonal values\n",
        "#here, we're taking the square root of the diagonal values, which are the standard deviation squared\n",
        "unc = np.sqrt(np.diag(cov))\n",
        "\n",
        "print(\"param1_err =\",unc[0],\"param2_err =\", unc[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1dmu1ulp5Jt"
      },
      "source": [
        "**Given what your data looks like, do you think these numbers are reasonable? Do your fit parameters to the noisy data agree with the real parameters within this uncertainty?**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comment here"
      ],
      "metadata": {
        "id": "mKZ9mnd1e7aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEv3xIgjp5Jt"
      },
      "source": [
        "## 2.3 Interpolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWV6uG3Zp5Jt"
      },
      "source": [
        "Now let's switch gears a little bit. Suppose we have some data where instead of function parameters (slopes, y-intercepts, etc.), we want to approximate what the values between our data points are. So in this case, we don't care about the specifics of the fit, we just want to connect the dots. This can be achieved using *interpolation* techniques. \n",
        "\n",
        "First, lets again create some data that follows a known function:\n",
        "1. **Using numpy arrays, create an array of 8 x values that ranges from 0 to 2$\\pi$**\n",
        "2. **Create an array of y values which is the sine of the x values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erwTDgydp5Jt"
      },
      "outputs": [],
      "source": [
        "#array of x values\n",
        "x_values = #complete\n",
        "\n",
        "#array of y values\n",
        "y_values = #complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgOWoSARp5Jt"
      },
      "source": [
        "As per *always*, make a scatter plot of your data before doing anything else."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DVq-5ojp5Jt"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "#complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOv8zwN-p5Ju"
      },
      "source": [
        "This could be sine curve - and I'm sure if you connected the dots by hand you would draw something that resembles a sine function. But let's see how well we can approximate this by numerically interpolating. To start, let's use the default settings of *interp_1d*. When passed x and y values, *interp_1d* will return a function which interpolates the data at every point between the maximum and minimum x value. We can then plot the values of this interpolation function over a range of test x values. \n",
        "\n",
        "1. **Pass *interp1d* your x and y values (see documentation here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp1d.html#scipy.interpolate.interp1d)**\n",
        "2. **Create an array of 500 n test x values between 0 and 2$\\pi$**\n",
        "3. **Pass your interpolation function your array of test x values and store the result as test y values**\n",
        "4. **Plot your test values as a line over a scatter plot of your data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zs55wj-p5Ju"
      },
      "outputs": [],
      "source": [
        "#create an interpolation function\n",
        "interp_func = interp1d(#complete\n",
        "\n",
        "#array of test x values\n",
        "x_test_values = #complete\n",
        "\n",
        "#recall that interp_func is a function, so it can be used like any other function\n",
        "y_test_values = #complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl8HU-qOp5Ju"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "#complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmr_2a1fp5Ju"
      },
      "source": [
        "As you can see, *interp_1d* connects the data points with straight lines by default. This isn't always the best way to interpolate data; based on how we generated it, we already know that our data has some curvature to it. It's also generally better to interpolate data smoothly, because this makes performing operations like differentiation easier/more accurate. Lets try out some different types of interpolation.\n",
        "\n",
        "To change the way *interp_1d* connects our data points, we can use the 'kind' option. By default this option is 'linear'.\n",
        "1. **Try setting 'kind' to each of the following: 'zero', 'quadratic', 'cubic'. For each different kind, create a new variable name to store the interpolating function in.**\n",
        "2. **Using the same method as above, plot the data and the interpolated approximation on top of each other. You can use the same test x values, but will need to create new test y values for each plot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4ZrnhH3p5Ju"
      },
      "outputs": [],
      "source": [
        "interp_func_zero = interp1d(\n",
        "#repeat for all interpolation kinds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9XT0thGp5Ju"
      },
      "outputs": [],
      "source": [
        "#test y values\n",
        "\n",
        "#zero plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKCSNZAvp5Jv"
      },
      "outputs": [],
      "source": [
        "#test y values\n",
        "\n",
        "#quadratic plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI6s0SqFp5Jv"
      },
      "outputs": [],
      "source": [
        "#test y values\n",
        "\n",
        "#cubic plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z33JMnPUp5Jv"
      },
      "source": [
        "How can we judge which of these kinds of interpolation is the best? We know what the values of the function *should* be, so we can compute the average uncertainty using something called the root-mean-square deviation (RMSD). This follows the formula:\n",
        "\n",
        "\\begin{equation*}RMSD = \\sqrt{\\frac{\\sum (y_{real} - y_{model})^2}{N}} \\end{equation*}\n",
        "\n",
        "\n",
        "Here, the model values will be the values predicted by the interpolating functions, and N will be the number of points in these arrays (should be 500). In the cell below, check to see how different each of the approximate y values are from the real values. \n",
        "\n",
        "1. **To generate an array of true y values, take the sine of your test x values**\n",
        "2. **For each of the interpolation functions, compute and store in different variables the RMSD**\n",
        "3. **Print each of the RMSD values, along with the interpolation method they correspond to**\n",
        "\n",
        "*Hint: compute the sum using np.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7hrxgNpp5Jv"
      },
      "outputs": [],
      "source": [
        "#real y values\n",
        "y_real_value = \n",
        "\n",
        "\n",
        "rmsd_value_linear = \n",
        "\n",
        "#repeat for all interpolation functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux7pR0Kep5Jv"
      },
      "source": [
        "Based on this, which appears to be the best kind of interpolation? This happens to be the best kind in general (and my favorite interpolation method :)). \n",
        "\n",
        "*Optional*: We can also check to make sure the area under the curve is what we expect it to be. For a sine curve in the range 0 to 2$\\pi$, the total area should be zero - this is because half the the curve is above zero and half is below. In order to find the area under the curve, we can *integrate* it - SciPy also has functions to do this. The particular algorithm we're going to use is called *quad* (which is all around the most accurate in SciPy). *quad* takes as arguments the name of the function you want to integrate, the upper bound of the integration, and the lower bound of the integration. \n",
        "\n",
        "1. **For each of the interpolation functions, use quad to integrate from 0 to 2$\\pi$ (see documentation here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.quad.html#scipy.integrate.quad)**\n",
        "2. **Print out the result of each. Why do you think the results are what they are?**\n",
        "\n",
        "*Note: when doing things computationally, numbers smaller than or close to $10^{-16}$ are considered zero*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m-V53T6p5Jv"
      },
      "outputs": [],
      "source": [
        "res_linear, err = quad(#complete\n",
        "#repeat for all interpolation functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZBpq1Wvp5Jv"
      },
      "source": [
        "## 2.4 Root Finding \n",
        "\n",
        "Now let's talk - briefly - about something completely different. In math classes, you may have needed to find the zeros of functions before (set y equal to zero and solve for x). Finding zeros is very important in the area of numerical optimization - which we won't talk about explicity - but can often be more complicated than just setting y equal to zero and solving for x. In fact, when you have no functional form and just data points, you can't do this at all. \n",
        "\n",
        "And that's where SciPy comes in. Suppose we have some interpolating function which passes through zero, and we want to know approximately where. One of the best algorithms to do this is something called *Brent's method*. *Brent's method* will attempt to find where a function crosses zero in a given interval; it needs to know the endpoints to look between in order to work. \n",
        "\n",
        "First, lets create some data to try this out on:\n",
        "1. **Using numpy, create an array of 10 equally spaced x values between -2 and 2**\n",
        "2. **Create an array of y values that is the x values cubed plus 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGlPBzBAp5Jw"
      },
      "outputs": [],
      "source": [
        "#array of x values\n",
        "x_values = #complete\n",
        "\n",
        "#array of y values\n",
        "y_values = #complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOKoaNusp5Jw"
      },
      "source": [
        "Plot your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDUqN5lLp5Jw"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "#complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCy5WXoBp5Jw"
      },
      "source": [
        "Based on the plot, at what x value do you expect the zero point to be? \n",
        "\n",
        "Let's see what SciPy thinks. We're going to use a function called *brentq*. This function takes the name of the function you want the zero of, the upper bound of that function, and the lower bound of that function. So first, we need to interpolate the data, and then pass that interpolant to *brentq*.\n",
        "\n",
        "1. **Using the best interpolation kind from the previous section, create and store an interpolating function of your x and y data**\n",
        "2. **Pass *brentq* the name of your interpolating function, the lower bound of the function, and the upper bound of the function (see documentation here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.brentq.html#scipy.optimize.brentq)**\n",
        "3. **Print the result. Does this answer seem correct?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXDa3KR2p5Jw"
      },
      "outputs": [],
      "source": [
        "#interpolating function\n",
        "interp_func = interp1d(#complete\n",
        "\n",
        "#find zero using brentq\n",
        "x0 = brentq(#complete\n",
        "\n",
        "#print result\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6250AcXnp5Jw"
      },
      "source": [
        "## 2.5 Fun With Real Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02AmiJJ-p5Jw"
      },
      "source": [
        "Now let's tackle a (sort of) real-life example. Using the provided data file, we will attempt to fit the data it contains with a more complicated fit function. First, we will load and plot the data.\n",
        "\n",
        "1. **Use numpy to load the data and plot it (with error bars)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_o_LWfNp5Jw"
      },
      "outputs": [],
      "source": [
        "#load data and store it to an array\n",
        "#columns: x values, y values, y error\n",
        "data = #complete\n",
        "\n",
        "#split the data into separate x, y, and y_err arrays using numpy array slicing\n",
        "x_values = #complete\n",
        "y_values = #complete\n",
        "y_error = #complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSnRiu95p5Jx"
      },
      "outputs": [],
      "source": [
        "#plot. that. data\n",
        "plt.figure(figsize=(10, 8))\n",
        "#complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhs7sGgLp5Jx"
      },
      "source": [
        "What do you think this function looks like? Using your knowledge of regression, try to think of a fitting function which might model this data, and then fit that model to the data.\n",
        "\n",
        "1. **Define a fitting function, and fit it to the data using *curve_fit***\n",
        "2. **Print the best fit parameters and their uncertainties**\n",
        "3. **Plot the data and the fit on top of each other**\n",
        "\n",
        "*Hint: try to fit a higher order polynomial*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THQo_PuNp5Jx"
      },
      "outputs": [],
      "source": [
        "#create a fitting function\n",
        "def #complete\n",
        "\n",
        "#use curve fit to fit the function to the data\n",
        "result, cov = #complete\n",
        "\n",
        "#print the result and the uncertainties\n",
        "#you can probably just copy and paste code from the first section, with minor adjustments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADAbXrCZp5Jx"
      },
      "outputs": [],
      "source": [
        "#create test x values that span the total x range, and test y values from the fit\n",
        "\n",
        "#plot the data and the fit \n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "#complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbYdZ8YIp5Jx"
      },
      "source": [
        "**How well does your fit function look like it fits the data? If you want, try a different function and see if it fits better.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdl7aBwnp5Jx"
      },
      "source": [
        "This data - which represents part of the spectrum (units of flux vs. frequency) from an astophysical object - has a particular function that best fits it. In order to fit that function we're going to cheat a little and find the location of the peak, i.e. where the slope of the function equals zero. To do this, we need to first interpolate our data, and then find where the slope (or *derivative*) equals zero. \n",
        "\n",
        "1. **Interpolate the data using the best kind of interpolation**\n",
        "2. **Define a function that takes x values and returns the derivative of your interpolation function at those x values (already completed for you)**\n",
        "3. **Pass the derivative function to *brentq* (remember you need to pass it a lower and upper bound), and store the result. Print this result. Does it make sense?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-tovzBqp5Jx"
      },
      "outputs": [],
      "source": [
        "#interpolation function \n",
        "interp_func = interp1d(#complete\n",
        "\n",
        "#function which takes x values and returns derivative\n",
        "def deriv_func(x):\n",
        "    \n",
        "    deriv = derivative(interp_func, x, dx = 1e-6)\n",
        "    \n",
        "    return deriv\n",
        "\n",
        "#find root of derivative function \n",
        "x0 = brentq(#complete\n",
        "\n",
        "#print result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_7exMm8p5Jx"
      },
      "source": [
        "The function we want to fit to is something called a broken power law:\n",
        "\n",
        "\\begin{equation}f(x) = a ((x/x0)^{b1/-0.8} + (x/x0)^{b2/-0.8})^{-0.8},\\end{equation}\n",
        "\n",
        "where a, b1, and b2 are the three fit parameters. Now that we know x0, we can use *curve_fit* to find the remaining 3 parameters.\n",
        "\n",
        "1. **Define a function called 'broken_power_law' which takes x values, a, b1, and b2 as input and returns the values corresponding to the above expression**\n",
        "2. **Use *curve_fit* to fit this function to the data, *including the uncertainties on y*. Print the result and uncertainties**\n",
        "3. **Plot the data and the fit on top of each other. Would you say this fit is good or bad? Why or why not?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRGNliHxp5Jy"
      },
      "outputs": [],
      "source": [
        "#create a function to return the expression above\n",
        "def #complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOq4tF8Hp5Jy"
      },
      "outputs": [],
      "source": [
        "#fit the above function using curve fit\n",
        "#hint: if you aren't getting an answer that looks right, \n",
        "#try setting the p0 option to a list of initial guesses for a, b1, and b2\n",
        "#for example: p0=[10, 5, -3]\n",
        "\n",
        "result, cov = curve_fit(#complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2Bnvs-3p5Jy"
      },
      "outputs": [],
      "source": [
        "#create test x and y values \n",
        "\n",
        "#plot the data with error and the fit\n",
        "plt.figure(figsize=(10, 8))\n",
        "#complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXokqccdp5Jy"
      },
      "source": [
        "## More Fun Stuff: Bonus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOiG-g1zp5Jy"
      },
      "source": [
        "As far as cool and useful tools go, SciPy has a *ton* of other nifty functions (with decent documentation), for almost every application. The data above is from a course I took on radiative processes in astrophysics. You can learn various things about the object which produced this light curve by finding the slope of each side of the logarithm of the data. This is just one idea of something you can do with this data besides just fitting it.   \n",
        "\n",
        "See what else you can do with it!\n",
        "\n",
        "Some ideas:\n",
        "\n",
        "* try a different fitting function\n",
        "* interpolate the data\n",
        "* find the point where the slope of the data is zero\n",
        "* integrate/differentiate the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spOFjpO2p5Jz"
      },
      "outputs": [],
      "source": [
        "##play around with the data and see what you can do with it\n",
        "##if you need help or suggestions, don't hesitate to ask!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cR9zu9lp5Jz"
      },
      "source": [
        "## Resources \n",
        "\n",
        "A set of SciPy tutorials and documentation can be found here: https://docs.scipy.org/doc/scipy/reference/index.html\n",
        "\n",
        "The Scipy Lectures site also has a pretty comprehensive guide to all of the modules: https://scipy-lectures.org/intro/scipy.html\n",
        "\n",
        "Here is a nifty explanation of the difference between regression and interpolation (which I found useful): https://stats.stackexchange.com/questions/33659/how-is-interpolation-related-to-the-concept-of-regression\n",
        "\n",
        "Here is a lecture (which is honestly pretty heavy, but if you want to look through it you can) on numerical root finding methods: http://butler.cc.tut.fi/~piche/numa/lecture0506.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIC6Wqxip5Jz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Section_2_Intro_to_Scipy.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kEv3xIgjp5Jt",
        "gZBpq1Wvp5Jv",
        "6250AcXnp5Jw",
        "vXokqccdp5Jy",
        "8cR9zu9lp5Jz"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}