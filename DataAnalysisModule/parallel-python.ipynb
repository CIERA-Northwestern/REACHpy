{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python natively supports parallel processing using the `multiprocessing` module. Though this module can become arbitrarily complex, it works best in cases where you want to repeat the same task over and over again on large amounts of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we need to import a few tasks from the `multiprocessing` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pool function allows you to create a \"pool\" of processes that can execute tasks that they are told to. We can generate pool of processes by telling Python how many processes we want to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ ==  '__main__':\n",
    "    pool = Pool(processes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `multiprocessing` package also has a way to determine how many cores you have in your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "print(cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many CPUs does your computer have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the number of CPUs our computers have to determine how many processes to put into the Pool. It does not make much sense to have the number of processes be greater than the number of cores, as we can only pass out as many jobs as we have cores at a single time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets try to do something in parallel. We need to create a task for the processes to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And some data to run the task on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [0,1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `Pool.map` function to pass each of the values in the data list to the task function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "if __name__ ==  '__main__':\n",
    "    pool = Pool(processes=3)\n",
    "    output = pool.map(task, data)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put it all together, and also add in a timer to test the speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run in serial =  0.00018611999999862405\n",
      "Time to run in parallel =  0.0016886580000026186\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "output = []\n",
    "for i in range(len(data)):\n",
    "    output.append(task(data[i]))\n",
    "stop = timer()\n",
    "\n",
    "print(\"Time to run in serial = \", stop - start)\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = Pool(processes=3)\n",
    "    start = timer()\n",
    "    output = pool.map(task, data)\n",
    "    stop = timer()\n",
    "\n",
    "print(\"Time to run in parallel = \", stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did this produce a speedup? Probably not. There is a significant amount of overhead involved in passing data to and from the processes, much more than it takes to run the calculation. To make the code more efficient, we probably need a bigger problem. To prove this to yourself, try increasing the size of the data array and see if you can get a speed up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more complicated example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squaring the value of a number just isn't a big enough operation to make the overheads of sending data to and receiving data from the different processes. Lets now try an example that performs a much more intensive operation on the data: sorting. First we need to create a new task function. Here we will create a Numpy array with N randomly selected elements, and then sort it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def task(N):\n",
    " rand = np.random.RandomState(42) # Give a seed to reproduce results\n",
    " a = rand.rand(N) # Generate an array of size n\n",
    " return a.sort() # Sort the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each task takes the number of elements that should be randomly generated in an array. Lets start with 10 arrays, each with 5 elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 5 5 5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "sizes = np.repeat(5, 10)\n",
    "\n",
    "print(sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets try running the task on the list of sizes, first in serial and then again in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run in serial =  0.0008135669999944639\n",
      "Time to run in parallel =  0.0032308970000016757\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "output = []\n",
    "for i in range(len(sizes)):\n",
    "    output.append(task(sizes[i]))\n",
    "stop = timer()\n",
    "\n",
    "print(\"Time to run in serial = \", stop - start)\n",
    "\n",
    "if __name__ ==  '__main__':\n",
    "    pool = Pool(processes=3)\n",
    "    start = timer()\n",
    "    output = pool.map(task, sizes)\n",
    "    stop = timer()\n",
    "\n",
    "print(\"Time to run in parallel = \", stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parallel version is still slower! Try making the task even bigger by increasing the size of the arrays to be sorted. Can you find an array size for which the parallel computation becomes faster? How much faster can you make it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if you increase the number of processes you are using? Make a plot of the time it takes to run as a function of the number of processes you are using. How does this plot change if you change N?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
